{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02af65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import sklearn\n",
    "import math\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ea2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the npz file\n",
    "train_1 = np.load(\"data/train_data.npy\")\n",
    "train_2 = np.load(\"data/train_labels.npy\")\n",
    "train_df = DataFrame(train_1)\n",
    "del train_1\n",
    "train_lb_df = DataFrame(train_2)\n",
    "del train_2\n",
    "\n",
    "# For validation\n",
    "val_1 = np.load(\"data/eval_data.npy\")\n",
    "val_2 = np.load(\"data/eval_labels.npy\")\n",
    "val_df = DataFrame(val_1)\n",
    "del val_1\n",
    "val_lb_df = DataFrame(val_2)\n",
    "del val_2\n",
    "\n",
    "# for unit_test\n",
    "\n",
    "uni_df = train_df.iloc[100:,:]\n",
    "uni_lb_df = train_lb_df.iloc[100:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd185ca5",
   "metadata": {},
   "source": [
    "### To see the features importance\n",
    "By random forest algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69ee5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.095185\n",
      "49 0.057753\n",
      "0 0.048706\n",
      "18 0.023706\n",
      "47 0.019150\n",
      "21 0.018729\n",
      "46 0.018422\n",
      "45 0.017218\n",
      "43 0.016490\n",
      "6 0.016352\n",
      "52 0.015682\n",
      "41 0.015469\n",
      "9 0.014890\n",
      "48 0.014589\n",
      "54 0.014339\n",
      "22 0.013709\n",
      "10 0.013667\n",
      "39 0.013586\n",
      "11 0.013571\n",
      "51 0.013370\n",
      "25 0.013327\n",
      "38 0.013234\n",
      "23 0.013207\n",
      "20 0.013116\n",
      "50 0.013089\n",
      "63 0.013043\n",
      "53 0.013013\n",
      "37 0.012943\n",
      "7 0.012797\n",
      "28 0.012759\n",
      "19 0.012742\n",
      "8 0.012593\n",
      "66 0.012492\n",
      "13 0.012392\n",
      "35 0.011987\n",
      "4 0.011940\n",
      "12 0.011888\n",
      "26 0.011841\n",
      "32 0.011759\n",
      "29 0.011734\n",
      "1 0.011686\n",
      "44 0.011672\n",
      "62 0.011596\n",
      "42 0.011472\n",
      "27 0.011305\n",
      "67 0.011251\n",
      "64 0.011158\n",
      "30 0.011042\n",
      "68 0.010927\n",
      "33 0.010921\n",
      "36 0.010892\n",
      "34 0.010874\n",
      "40 0.010805\n",
      "69 0.010652\n",
      "65 0.010623\n",
      "31 0.010577\n",
      "61 0.010491\n",
      "14 0.009905\n",
      "15 0.009512\n",
      "5 0.009510\n",
      "56 0.009018\n",
      "16 0.008982\n",
      "2 0.008759\n",
      "17 0.008314\n",
      "3 0.007885\n",
      "58 0.005100\n",
      "57 0.004243\n",
      "59 0.001958\n",
      "60 0.001336\n",
      "55 0.001057\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70 entries, 24 to 55\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   feature_name  70 non-null     int64  \n",
      " 1   importance    70 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Load the forest\n",
    "import joblib\n",
    "forest = joblib.load( \"Model/01_RF_training_350sqrt\" )\n",
    "ft_imp = pd.DataFrame(forest.feature_importances_)\n",
    "ft_imp.index = train_df.columns\n",
    "ft_imp = ft_imp.sort_values(0, ascending=False)\n",
    "ft_imp[\"feature_name\"] = ft_imp.index\n",
    "ft_imp[\"importance\"] = ft_imp.iloc[:,0]\n",
    "ft_imp = ft_imp[ [\"feature_name\", \"importance\"] ]\n",
    "for i in range(len(ft_imp)):\n",
    "    print(\"%s %0.6f\" % (str(ft_imp.iloc[i,0]), ft_imp.iloc[i,1]))\n",
    "    #print(ft_imp.iloc[i,0])\n",
    "ft_imp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f9024",
   "metadata": {},
   "source": [
    "### Abandon the feature with < 0.005 importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b28590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1174461 entries, 0 to 1174460\n",
      "Data columns (total 66 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   0       1174461 non-null  float64\n",
      " 1   1       1174461 non-null  float64\n",
      " 2   2       1174461 non-null  float64\n",
      " 3   3       1174461 non-null  float64\n",
      " 4   4       1174461 non-null  float64\n",
      " 5   5       1174461 non-null  float64\n",
      " 6   6       1174461 non-null  float64\n",
      " 7   7       1174461 non-null  float64\n",
      " 8   8       1174461 non-null  float64\n",
      " 9   9       1174461 non-null  float64\n",
      " 10  10      1174461 non-null  float64\n",
      " 11  11      1174461 non-null  float64\n",
      " 12  12      1174461 non-null  float64\n",
      " 13  13      1174461 non-null  float64\n",
      " 14  14      1174461 non-null  float64\n",
      " 15  15      1174461 non-null  float64\n",
      " 16  16      1174461 non-null  float64\n",
      " 17  17      1174461 non-null  float64\n",
      " 18  18      1174461 non-null  float64\n",
      " 19  19      1174461 non-null  float64\n",
      " 20  20      1174461 non-null  float64\n",
      " 21  21      1174461 non-null  float64\n",
      " 22  22      1174461 non-null  float64\n",
      " 23  23      1174461 non-null  float64\n",
      " 24  24      1174461 non-null  float64\n",
      " 25  25      1174461 non-null  float64\n",
      " 26  26      1174461 non-null  float64\n",
      " 27  27      1174461 non-null  float64\n",
      " 28  28      1174461 non-null  float64\n",
      " 29  29      1174461 non-null  float64\n",
      " 30  30      1174461 non-null  float64\n",
      " 31  31      1174461 non-null  float64\n",
      " 32  32      1174461 non-null  float64\n",
      " 33  33      1174461 non-null  float64\n",
      " 34  34      1174461 non-null  float64\n",
      " 35  35      1174461 non-null  float64\n",
      " 36  36      1174461 non-null  float64\n",
      " 37  37      1174461 non-null  float64\n",
      " 38  38      1174461 non-null  float64\n",
      " 39  39      1174461 non-null  float64\n",
      " 40  40      1174461 non-null  float64\n",
      " 41  41      1174461 non-null  float64\n",
      " 42  42      1174461 non-null  float64\n",
      " 43  43      1174461 non-null  float64\n",
      " 44  44      1174461 non-null  float64\n",
      " 45  45      1174461 non-null  float64\n",
      " 46  46      1174461 non-null  float64\n",
      " 47  47      1174461 non-null  float64\n",
      " 48  48      1174461 non-null  float64\n",
      " 49  49      1174461 non-null  float64\n",
      " 50  50      1174461 non-null  float64\n",
      " 51  51      1174461 non-null  float64\n",
      " 52  52      1174461 non-null  float64\n",
      " 53  53      1174461 non-null  float64\n",
      " 54  54      1174461 non-null  float64\n",
      " 55  56      1174461 non-null  float64\n",
      " 56  58      1174461 non-null  float64\n",
      " 57  61      1174461 non-null  float64\n",
      " 58  62      1174461 non-null  float64\n",
      " 59  63      1174461 non-null  float64\n",
      " 60  64      1174461 non-null  float64\n",
      " 61  65      1174461 non-null  float64\n",
      " 62  66      1174461 non-null  float64\n",
      " 63  67      1174461 non-null  float64\n",
      " 64  68      1174461 non-null  float64\n",
      " 65  69      1174461 non-null  float64\n",
      "dtypes: float64(66)\n",
      "memory usage: 591.4 MB\n"
     ]
    }
   ],
   "source": [
    "imp_notdrop_list = [ x for x in range(70) if x not in [55,57,59,60] ]\n",
    "train_df = train_df[imp_notdrop_list]\n",
    "val_df = val_df[imp_notdrop_list]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caee2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare i and j\n",
    "def Training_EnsembleModel(X, y, i=0, j=1, n_events=100000, name=\"\" ):\n",
    "    \"\"\"\n",
    "    import random\n",
    "    start_idx = random.randrange(len(train_lb_df)-n_events)\n",
    "    end_idx = start_idx + n_events\n",
    "    \n",
    "    print(\"training events start and end point : %f, %f\" %(start_idx, end_idx))\n",
    "    \n",
    "    X = train_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & ((train_lb_df.index>=start_idx) & (train_lb_df.index<end_idx)),:]\n",
    "    y = train_lb_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & ((train_lb_df.index>=start_idx) & (train_lb_df.index<end_idx)),0]\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \"\"\"\n",
    "    #X = train_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),:]\n",
    "    #y = train_lb_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),0]\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "    \n",
    "    lr = LogisticRegression(C=0.001)\n",
    "    pipeline = make_pipeline(StandardScaler(), lr)\n",
    "    \n",
    "    forest = RandomForestClassifier( n_estimators=350, max_features=None, criterion='gini', random_state=22, n_jobs=-1 )\n",
    "    \n",
    "    tree = DecisionTreeClassifier( random_state=1, max_depth=12, max_features=\"sqrt\", max_leaf_nodes=None )\n",
    "    ABC = AdaBoostClassifier( base_estimator=tree, random_state=11, learning_rate=0.1, n_estimators=70 )\n",
    "    \n",
    "    \"\"\"\n",
    "    lr = LogisticRegression(C=lr_c)\n",
    "    pipeline = make_pipeline(StandardScaler(), lr)\n",
    "    \n",
    "    forest = RandomForestClassifier( n_estimators=rf_nest, max_features=rf_maxf, criterion='gini', random_state=22, n_jobs=-1 )\n",
    "    \n",
    "    tree = DecisionTreeClassifier( random_state=1, max_depth=bdt_maxd, max_features=bdt_maxf, max_leaf_nodes=bdt_maxl )\n",
    "    ABC = AdaBoostClassifier( base_estimator=tree, random_state=11, learning_rate=bdt_lr, n_estimators=bdt_nest )\n",
    "    \"\"\"\n",
    "    model = VotingClassifier(estimators=[\n",
    "            ('lr', pipeline), ('rf', forest), ('bdt', ABC)],\n",
    "            voting='soft')\n",
    "    model = model.fit( train_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),:], train_lb_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),0])\n",
    "    joblib.dump( model, \"01_final_Ensemble_training_afterCut_\" + str(i) + \"_\" + str(j) + \"_\" + name )\n",
    "    print(\"Accuracy : \", accuracy_score(val_lb_df.loc[(val_lb_df[0]==i)|(val_lb_df[0]==j),:],  model.predict(val_df.loc[(val_lb_df[0]==i)|(val_lb_df[0]==j),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336c583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7416534001483438\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n_events = 100000\n",
    "start_idx = random.randrange(len(train_lb_df)-n_events)\n",
    "end_idx = start_idx + n_events\n",
    "Training_EnsembleModel(train_df.loc[((train_lb_df[0]==0)|(train_lb_df[0]==1)) & ((train_lb_df.index>=start_idx) & (train_lb_df.index<end_idx)),:],\n",
    "                       train_lb_df.loc[((train_lb_df[0]==0)|(train_lb_df[0]==1)) & ((train_lb_df.index>=start_idx) & (train_lb_df.index<end_idx)),0],\n",
    "                       0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
