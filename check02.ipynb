{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab41700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import sklearn\n",
    "import math\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd525a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the npz file\n",
    "train_1 = np.load(\"data/train_data.npy\")\n",
    "train_2 = np.load(\"data/train_labels.npy\")\n",
    "train_df = DataFrame(train_1)\n",
    "del train_1\n",
    "train_lb_df = DataFrame(train_2)\n",
    "del train_2\n",
    "\n",
    "# For validation\n",
    "val_1 = np.load(\"data/eval_data.npy\")\n",
    "val_2 = np.load(\"data/eval_labels.npy\")\n",
    "val_df = DataFrame(val_1)\n",
    "del val_1\n",
    "val_lb_df = DataFrame(val_2)\n",
    "del val_2\n",
    "\n",
    "# for unit_test\n",
    "\n",
    "uni_df = train_df.iloc[100:,:]\n",
    "uni_lb_df = train_lb_df.iloc[100:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04a885",
   "metadata": {},
   "source": [
    "### To see the features importance\n",
    "By random forest algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f47a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.185934\n",
      "49 0.043888\n",
      "0 0.018761\n",
      "50 0.018217\n",
      "52 0.017221\n",
      "54 0.016561\n",
      "8 0.015748\n",
      "6 0.015664\n",
      "63 0.015401\n",
      "43 0.015201\n",
      "9 0.014880\n",
      "53 0.014763\n",
      "48 0.014364\n",
      "18 0.014254\n",
      "47 0.013960\n",
      "46 0.013954\n",
      "28 0.013883\n",
      "21 0.013323\n",
      "13 0.013307\n",
      "19 0.013262\n",
      "20 0.013218\n",
      "25 0.013091\n",
      "22 0.012969\n",
      "7 0.012937\n",
      "66 0.012907\n",
      "4 0.012872\n",
      "23 0.012868\n",
      "41 0.012827\n",
      "35 0.012590\n",
      "39 0.012398\n",
      "37 0.012393\n",
      "29 0.012334\n",
      "68 0.012291\n",
      "10 0.012225\n",
      "26 0.012144\n",
      "45 0.012039\n",
      "11 0.011961\n",
      "38 0.011806\n",
      "34 0.011662\n",
      "32 0.011610\n",
      "30 0.011327\n",
      "36 0.011323\n",
      "51 0.011281\n",
      "67 0.011272\n",
      "27 0.011267\n",
      "62 0.011215\n",
      "69 0.011161\n",
      "44 0.011099\n",
      "64 0.011059\n",
      "33 0.010841\n",
      "61 0.010561\n",
      "16 0.010168\n",
      "42 0.010017\n",
      "31 0.009997\n",
      "65 0.009834\n",
      "1 0.009415\n",
      "12 0.009379\n",
      "40 0.009338\n",
      "14 0.009186\n",
      "2 0.008308\n",
      "15 0.008159\n",
      "3 0.008142\n",
      "17 0.007996\n",
      "5 0.005181\n",
      "58 0.003286\n",
      "55 0.002541\n",
      "57 0.001897\n",
      "59 0.001812\n",
      "60 0.001009\n",
      "56 0.000243\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70 entries, 24 to 56\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   feature_name  70 non-null     int64  \n",
      " 1   importance    70 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Load the forest\n",
    "import joblib\n",
    "forest = joblib.load( \"Model/02_RF_training_300_0pt7\" )\n",
    "ft_imp = pd.DataFrame(forest.feature_importances_)\n",
    "ft_imp.index = train_df.columns\n",
    "ft_imp = ft_imp.sort_values(0, ascending=False)\n",
    "ft_imp[\"feature_name\"] = ft_imp.index\n",
    "ft_imp[\"importance\"] = ft_imp.iloc[:,0]\n",
    "ft_imp = ft_imp[ [\"feature_name\", \"importance\"] ]\n",
    "for i in range(len(ft_imp)):\n",
    "    print(\"%s %0.6f\" % (str(ft_imp.iloc[i,0]), ft_imp.iloc[i,1]))\n",
    "    #print(ft_imp.iloc[i,0])\n",
    "ft_imp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef2b28f",
   "metadata": {},
   "source": [
    "### Abandon the feature with < 0.005 importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2c9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1174461 entries, 0 to 1174460\n",
      "Data columns (total 64 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   0       1174461 non-null  float64\n",
      " 1   1       1174461 non-null  float64\n",
      " 2   2       1174461 non-null  float64\n",
      " 3   3       1174461 non-null  float64\n",
      " 4   4       1174461 non-null  float64\n",
      " 5   5       1174461 non-null  float64\n",
      " 6   6       1174461 non-null  float64\n",
      " 7   7       1174461 non-null  float64\n",
      " 8   8       1174461 non-null  float64\n",
      " 9   9       1174461 non-null  float64\n",
      " 10  10      1174461 non-null  float64\n",
      " 11  11      1174461 non-null  float64\n",
      " 12  12      1174461 non-null  float64\n",
      " 13  13      1174461 non-null  float64\n",
      " 14  14      1174461 non-null  float64\n",
      " 15  15      1174461 non-null  float64\n",
      " 16  16      1174461 non-null  float64\n",
      " 17  17      1174461 non-null  float64\n",
      " 18  18      1174461 non-null  float64\n",
      " 19  19      1174461 non-null  float64\n",
      " 20  20      1174461 non-null  float64\n",
      " 21  21      1174461 non-null  float64\n",
      " 22  22      1174461 non-null  float64\n",
      " 23  23      1174461 non-null  float64\n",
      " 24  24      1174461 non-null  float64\n",
      " 25  25      1174461 non-null  float64\n",
      " 26  26      1174461 non-null  float64\n",
      " 27  27      1174461 non-null  float64\n",
      " 28  28      1174461 non-null  float64\n",
      " 29  29      1174461 non-null  float64\n",
      " 30  30      1174461 non-null  float64\n",
      " 31  31      1174461 non-null  float64\n",
      " 32  32      1174461 non-null  float64\n",
      " 33  33      1174461 non-null  float64\n",
      " 34  34      1174461 non-null  float64\n",
      " 35  35      1174461 non-null  float64\n",
      " 36  36      1174461 non-null  float64\n",
      " 37  37      1174461 non-null  float64\n",
      " 38  38      1174461 non-null  float64\n",
      " 39  39      1174461 non-null  float64\n",
      " 40  40      1174461 non-null  float64\n",
      " 41  41      1174461 non-null  float64\n",
      " 42  42      1174461 non-null  float64\n",
      " 43  43      1174461 non-null  float64\n",
      " 44  44      1174461 non-null  float64\n",
      " 45  45      1174461 non-null  float64\n",
      " 46  46      1174461 non-null  float64\n",
      " 47  47      1174461 non-null  float64\n",
      " 48  48      1174461 non-null  float64\n",
      " 49  49      1174461 non-null  float64\n",
      " 50  50      1174461 non-null  float64\n",
      " 51  51      1174461 non-null  float64\n",
      " 52  52      1174461 non-null  float64\n",
      " 53  53      1174461 non-null  float64\n",
      " 54  54      1174461 non-null  float64\n",
      " 55  61      1174461 non-null  float64\n",
      " 56  62      1174461 non-null  float64\n",
      " 57  63      1174461 non-null  float64\n",
      " 58  64      1174461 non-null  float64\n",
      " 59  65      1174461 non-null  float64\n",
      " 60  66      1174461 non-null  float64\n",
      " 61  67      1174461 non-null  float64\n",
      " 62  68      1174461 non-null  float64\n",
      " 63  69      1174461 non-null  float64\n",
      "dtypes: float64(64)\n",
      "memory usage: 573.5 MB\n"
     ]
    }
   ],
   "source": [
    "imp_notdrop_list = [ x for x in range(70) if x not in range(55,61) ]\n",
    "train_df = train_df[imp_notdrop_list]\n",
    "val_df = val_df[imp_notdrop_list]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44100bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare i and j\n",
    "def Training_EnsembleModel(X, y, i=0, j=1, name=\"\" ):\n",
    "    \n",
    "    #X = train_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),:]\n",
    "    #y = train_lb_df.loc[((train_lb_df[0]==i)|(train_lb_df[0]==j)) & (train_lb_df.index>1000000),0]\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "    \n",
    "    lr = LogisticRegression(C=0.001)\n",
    "    pipeline = make_pipeline(StandardScaler(), lr)\n",
    "    \n",
    "    forest = RandomForestClassifier( n_estimators=300, max_features=0.7, criterion='gini', random_state=22, n_jobs=-1 )\n",
    "    \n",
    "    tree = DecisionTreeClassifier( random_state=1, max_depth=18, max_features=\"sqrt\", max_leaf_nodes=None )\n",
    "    ABC = AdaBoostClassifier( base_estimator=tree, random_state=11, learning_rate=0.1, n_estimators=50 )\n",
    "    \n",
    "    model = VotingClassifier(estimators=[\n",
    "            ('lr', pipeline), ('rf', forest), ('bdt', ABC)],\n",
    "            voting='soft')\n",
    "    model = model.fit(X, y)\n",
    "    joblib.dump( model, \"02_final_Ensemble_training_afterCut_\" + str(i) + \"_\" + str(j) + \"_\" + name )\n",
    "    print(\"Accuracy : \", accuracy_score(val_lb_df.loc[(val_lb_df[0]==i)|(val_lb_df[0]==j),:],  model.predict(val_df.loc[(val_lb_df[0]==i)|(val_lb_df[0]==j),:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eed589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7007275471437378\n"
     ]
    }
   ],
   "source": [
    "par_02 = [0.001, 300, 0.7, 50, 0.1, 18, \"sqrt\", None]\n",
    "Training_EnsembleModel(train_df.loc[((train_lb_df[0]==0)|(train_lb_df[0]==2)) & (train_lb_df.index>1000000),:]\n",
    "                       , train_lb_df.loc[((train_lb_df[0]==0)|(train_lb_df[0]==2)) & (train_lb_df.index>1000000),0]\n",
    "                       , 0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
